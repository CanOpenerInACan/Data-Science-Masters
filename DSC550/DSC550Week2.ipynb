{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Lattimer  \n",
    "12/9/2020  \n",
    "DSC 550  \n",
    "# Week 2 Exercise 2.2\n",
    "1. You can find the dataset controversial-comments.jsonl for this exercise in the Weekly Resources: Week 2 Data Files.\n",
    "\n",
    "Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame. Then,\n",
    "\n",
    "* Convert all text to lowercase letters.\n",
    "\n",
    "* Remove all punctuation from the text.\n",
    "\n",
    "* Remove stop words.\n",
    "\n",
    "* Apply NLTK’s PorterStemmer.\n",
    "\n",
    "Now that the data is pre-processed, you will apply three different techniques to get it into a usable form for model-building. Apply each of the following steps (individually) to the pre-processed data.\n",
    "\n",
    "* Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "* Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "* Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "Follow-Up Question\n",
    "\n",
    "For the three techniques in problem (2) above, give an example where each would be useful.\n",
    "\n",
    "NOTE\n",
    "\n",
    "Running these steps on all of the data can take a while, so feel free to cut down on the number of texts (maybe 50,000) if your program takes too long to run. But be sure to select the text entries randomly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_json('controversial-comments.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"txt\"] = df[\"txt\"].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['txt'] = df['txt'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[well, great, something, beliefs, office., dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[right, mr., president.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[given, input, apart, saying, wrong., argument...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[get, frustration, reason, want, way, foundati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[far, expert, tpp, would, tend, agree, lot, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>0</td>\n",
       "      <td>[genuinely, can't, understand, anyone, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>0</td>\n",
       "      <td>[reminder,, subreddit, [is, civil, discussion....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>0</td>\n",
       "      <td>[k., explain, anything.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>0</td>\n",
       "      <td>[[deleted]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>0</td>\n",
       "      <td>[ya,, sociopaths, known, celebrating, positive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  [well, great, something, beliefs, office., dou...\n",
       "1         0                           [right, mr., president.]\n",
       "2         0  [given, input, apart, saying, wrong., argument...\n",
       "3         0  [get, frustration, reason, want, way, foundati...\n",
       "4         0  [far, expert, tpp, would, tend, agree, lot, pr...\n",
       "...     ...                                                ...\n",
       "949995    0  [genuinely, can't, understand, anyone, support...\n",
       "949996    0  [reminder,, subreddit, [is, civil, discussion....\n",
       "949997    0                           [k., explain, anything.]\n",
       "949998    0                                        [[deleted]]\n",
       "949999    0  [ya,, sociopaths, known, celebrating, positive...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
